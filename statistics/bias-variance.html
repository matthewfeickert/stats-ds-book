
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <meta property="og:title" content="Bias-Variance Tradeoff" />
  <meta property="og:type" content="website" />
  <meta property="og:url" content="https://cranmer.github.io/stats-ds-book/statistics/bias-variance.html" />
  <meta property="og:description" content="One of the most important concepts in statistics and machine learning is the Bias-Variance tradeoff. Before we can discuss it, let’s define a few concepts. The bias of an estimator: If\theta has se..." />
  <meta property="og:image" content="https://cranmer.github.io/stats-ds-book/_images/Neyman-pearson.006.png" />
  <meta property="og:image:alt" content="Bias-Variance Tradeoff" />
  
    <title>Bias-Variance Tradeoff &#8212; Statistics and Data Science</title>
    
  <link rel="stylesheet" href="../_static/css/index.73d71520a4ca3b99cfee5594769eaaae.css">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      
  <link rel="stylesheet"
    href="../_static/vendor/open-sans_all/1.44.1/index.css">
  <link rel="stylesheet"
    href="../_static/vendor/lato_latin-ext/1.44.1/index.css">

    
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../_static/sphinx-book-theme.40e2e510f6b7d1648584402491bb10fe.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx_tabs/semantic-ui-2.4.1/segment.min.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx_tabs/semantic-ui-2.4.1/menu.min.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx_tabs/semantic-ui-2.4.1/tab.min.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx_tabs/tabs.css" />
    <link rel="stylesheet" type="text/css" href="../_static/pdf_print.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.3da636dd464baa7582d2.js">

    <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/language_data.js"></script>
    <script src="../_static/togglebutton.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/save_state.js"></script>
    <script async="async" kind="hypothesis" src="https://hypothes.is/embed.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/sphinx-book-theme.d31b09fe5c1d09cb49b26a786de4a05d.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/x-mathjax-config">MathJax.Hub.Config({"TeX": {"Macros": {"N": "\\mathbb{N}", "indep": "{\\perp\\kern-5pt\\perp}", "floor": ["\\lfloor#1\\rfloor", 1], "bmat": ["\\left[\\begin{array}"], "emat": ["\\end{array}\\right]"], "bered": ["\\color{#DC2830}{#1}", 1], "ecol": ["}}"]}}, "tex2jax": {"inlineMath": [["\\(", "\\)"]], "displayMath": [["\\[", "\\]"]], "processRefs": false, "processEnvironments": false}})</script>
    <script async="async" src="https://unpkg.com/thebelab@latest/lib/index.js"></script>
    <script >
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Investigation of Bessel’s correction" href="investigation-bessels-correction.html" />
    <link rel="prev" title="Estimators" href="estimators.html" />

    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />



  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
<a class="navbar-brand text-wrap" href="../index.html">
  
  <img src="../_static/logo.png" class="logo" alt="logo">
  
  
  <h1 class="site-logo" id="site-title">Statistics and Data Science</h1>
  
</a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form>
<nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
    <ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../intro.html">
   Statistics and Data Science
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  About the course
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../schedule.html">
   Draft Schedule
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../jupyterhub.html">
   JupyterHub for class
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../nbgrader.html">
   nbgrader
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../discussion_forum.html">
   Discussion Forum
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../preliminaries.html">
   Preliminaries
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Probability
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../probability-topics.html">
   Probability Topics
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../random_variables.html">
     Random Variables
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../conditional.html">
     Conditonal Probability
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../bayes_theorem.html">
     Bayes’ Theorem
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../independence.html">
     Independence
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../empirical_distribution.html">
     Empirical Distribution
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../expectation.html">
     Expectation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../correlation.html">
     Covariance and Correlation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../datasaurus-long.html">
     Simple data exploration
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../distributions/visualize_marginals.html">
     Visualizing joint and marginal distributions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../measures_of_dependence.html">
     Quantifying statistical dependence
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../distributions/change-of-variables.html">
     How do distributions transform under a change of variables ?
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../distributions/one-over-x-flow.html">
     Change of variables with autodiff
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../distributions/likelihood-change-obs.html">
     Transformation of likelihood with change of random variable
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../distributions/invariance-of-likelihood-to-reparameterizaton.html">
     Transformation properties of the likelihood and posterior
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../error-propagation/investigating-propagation-of-errors.html">
     Investigating propagation of errors
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../error-propagation/error_propagation_with_jax.html">
     Revisiting error propagation with automatic differentiation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../distributions/accept-reject.html">
     Accept / Reject Monte Carlo
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../distributions/Binomial_histograms-interactive.html">
     An interactive exploration of statistical fluctuations in histograms
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../pgm/daft.html">
     Visualizing Graphical Models
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Statistics
 </span>
</p>
<ul class="current nav sidenav_l1">
 <li class="toctree-l1 current active collapsible-parent">
  <a class="reference internal" href="../statistics-topics.html">
   Statistics Topics
  </a>
  <ul class="current collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="estimators.html">
     Estimators
    </a>
   </li>
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     Bias-Variance Tradeoff
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="investigation-bessels-correction.html">
     Investigation of Bessel’s correction
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="cramer-rao-bound.html">
     Cramér-Rao Bound
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="consistency.html">
     Consistency
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="sufficiency.html">
     Sufficiency
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="information-geometry.html">
     Information Geometry
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="neyman_pearson.html">
     Neyman-Pearson lemma
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="neyman_construction.html">
     Neyman construction
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="lhc_stats_thumbnail.html">
     Thumbnail of LHC Statistical Procedures
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="statistical_decision_theory.html">
     Statistical decision theory
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../probprog/MarkovPath.html">
     Universal Probabilistic Programming Example
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Machine Learning
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../prml_notebooks/attribution.html">
   PRML Examples
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../prml_notebooks/ch01_Introduction.html">
     1. Introduction
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../prml_notebooks/ch02_Probability_Distributions.html">
     2. Probability Distributions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../prml_notebooks/ch03_Linear_Models_for_Regression.html">
     3. Linear Models for Regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../prml_notebooks/ch04_Linear_Models_for_Classfication.html">
     4. Linear Models for Classification
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../prml_notebooks/ch05_Neural_Networks.html">
     5. Neural Networks
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../prml_notebooks/ch06_Kernel_Methods.html">
     6. Kernel Methods
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../prml_notebooks/ch07_Sparse_Kernel_Machines.html">
     7. Sparse Kernel Machines
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../prml_notebooks/ch08_Graphical_Models.html">
     8. Graphical Models
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../prml_notebooks/ch09_Mixture_Models_and_EM.html">
     9. Mixture Models and EM
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../prml_notebooks/ch10_Approximate_Inference.html">
     10. Approximate Inference
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../prml_notebooks/ch11_Sampling_Methods.html">
     11. Sampling Methods
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../prml_notebooks/ch12_Continuous_Latent_Variables.html">
     12. Continuous Latent Variables
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../prml_notebooks/ch13_Sequential_Data.html">
     13. Sequential Data
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Software and Computing
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../computing-topics.html">
   Software &amp; Computing Topics
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../autodiff-tutorial.html">
   Tutorial on Automatic Differentiation
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Data Science
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../data-science-topics.html">
   Data Science, what is it?
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  References
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../other_resources.html">
   Other Resources
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../bibliography.html">
   Bibliography
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../built-on.html">
   Built on
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Jupyter Book Reference
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../markdown.html">
   Markdown Files
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../cheatsheet.html">
   MyST Cheat Sheet
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../notebooks.html">
   Content with notebooks
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../interactive.html">
   Interactive data visualizations
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../test_embed_video.html">
   Test Embed Video
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../color-in-equations.html">
   Color in equations
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../test-sphinxext-opengraph.html">
   Test Sphinxext-opengraph
  </a>
 </li>
</ul>

</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="row topbar fixed-top container-xl">
    <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show">
    </div>
    <div class="col pl-2 topbar-main">
        
        <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
            data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
            aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
            title="Toggle navigation" data-toggle="tooltip" data-placement="left">
            <i class="fas fa-bars"></i>
            <i class="fas fa-arrow-left"></i>
            <i class="fas fa-arrow-up"></i>
        </button>
        
        
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../_sources/statistics/bias-variance.md"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.md</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

        <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        <a class="repository-button"
            href="https://github.com/cranmer/stats-ds-book"><button type="button" class="btn btn-secondary topbarbtn"
                data-toggle="tooltip" data-placement="left" title="Source repository"><i
                    class="fab fa-github"></i>repository</button></a>
        <a class="issues-button"
            href="https://github.com/cranmer/stats-ds-book/issues/new?title=Issue%20on%20page%20%2Fstatistics/bias-variance.html&body=Your%20issue%20content%20here."><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Open an issue"><i class="fas fa-lightbulb"></i>open issue</button></a>
        <a class="edit-button" href="https://github.com/cranmer/stats-ds-book/edit/master/book/statistics/bias-variance.md"><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Edit this page"><i class="fas fa-pencil-alt"></i>suggest edit</button></a>
    </div>
</div>


        <!-- Full screen (wrap in <a> to have style consistency -->
        <a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
                data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
                title="Fullscreen mode"><i
                    class="fas fa-expand"></i></button></a>

        <!-- Launch buttons -->

    </div>

    <!-- Table of contents -->
    <div class="d-none d-md-block col-md-2 bd-toc show">
        
        <div class="tocsection onthispage pt-5 pb-3">
            <i class="fas fa-list"></i> Contents
        </div>
        <nav id="bd-toc-nav">
            <ul class="nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#the-bias-of-an-estimator">
   The bias of an estimator
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#the-variance-of-an-estimator">
   The variance of an estimator
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#the-mean-squared-error-of-an-estimator">
   The mean squared error of an estimator
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#the-bias-variance-tradeoff">
   The bias-variance tradeoff
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#asymptotic-bias-and-variance">
   Asymptotic bias and variance
  </a>
 </li>
</ul>

        </nav>
        
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="section" id="bias-variance-tradeoff">
<h1>Bias-Variance Tradeoff<a class="headerlink" href="#bias-variance-tradeoff" title="Permalink to this headline">¶</a></h1>
<p>One of the most important concepts in statistics and machine learning is the Bias-Variance tradeoff.
Before we can discuss it, let’s define a few concepts.</p>
<div class="section" id="the-bias-of-an-estimator">
<h2>The bias of an estimator<a class="headerlink" href="#the-bias-of-an-estimator" title="Permalink to this headline">¶</a></h2>
<div class="admonition-bias-of-an-estimator admonition">
<p class="admonition-title">Bias of an estimator</p>
<p>The bias of an estimator, denoted <span class="math notranslate nohighlight">\(\textrm{bias}(\hat{\theta} \mid \theta)\)</span>, is defined as:</p>
<div class="math notranslate nohighlight">
\[
\textrm{bias}(\hat{\theta} \mid \theta) = \mathbb{E}[\hat{\theta} \mid \theta ] - \theta = \mathbb{E}[\hat{\theta} - \theta \mid \theta ]  =\int (\hat{\theta}(x) - \theta) p(x | \theta) dx
\]</div>
<p><strong>Note</strong> the bias isn’t a single number, but a function of the true, unknown value of <span class="math notranslate nohighlight">\(\theta\)</span>. Sometimes the estimator is implicit and you may see the bias denoted <span class="math notranslate nohighlight">\(b(\theta)\)</span>, or the dependence on <span class="math notranslate nohighlight">\(\theta\)</span> is left implicit and you may see it denoted <span class="math notranslate nohighlight">\(b(\hat{\theta})\)</span>.</p>
</div>
<p>If <span class="math notranslate nohighlight">\(\theta\)</span> has several components, the expectations and bias are calculated per component.</p>
<div class="admonition-terminology admonition">
<p class="admonition-title">Terminology</p>
<p>If the bias is 0 for all values of <span class="math notranslate nohighlight">\(\theta\)</span>, the estimator is said to be <strong>unbiased</strong>.</p>
</div>
<p>Usually physicists would react poorly to a biased estimator.
This is partially due to the fact that “bias” is a loaded term with negative connotations.
We will come back to this later… how bad is it if your estimator is biased?</p>
</div>
<div class="section" id="the-variance-of-an-estimator">
<h2>The variance of an estimator<a class="headerlink" href="#the-variance-of-an-estimator" title="Permalink to this headline">¶</a></h2>
<div class="admonition-variance-of-an-estimator admonition">
<p class="admonition-title">Variance of an estimator</p>
<p>The variance of an estimator uses the same definition as the variance of any random variable</p>
<div class="math notranslate nohighlight">
\[
\textrm{var}(\hat{\theta} \mid \theta) = \mathbb{E}[\left( \hat{\theta} - \mathbb{E}[\hat{\theta}\mid \theta ] \right)^2 \mid \theta ] 
\]</div>
<p><strong>Note</strong> the variance also depends on the true, unknown value of <span class="math notranslate nohighlight">\(\theta\)</span>.</p>
</div>
<p>If <span class="math notranslate nohighlight">\(\theta\)</span> has several components, the notion of variance is generalized to <span class="xref myst">covariance</span> as for any other multivariate random variable.</p>
<p>Intuitively, we would like the variance of the estimator to be small
Interestingly, there is a theoretical lower bound on the variance of an estimator, which is called the <span class="xref myst">Cramér-Rao bound</span>.
Just because the variance of an estimator is small, doesn’t mean that it’s close to the true value.
For instance, our straw man constant estimator <span class="math notranslate nohighlight">\(\hat{\theta}_\textrm{const} = \theta_0\)</span> has zero variance, but it’s not very userful.</p>
<p>Note, this is closely connected to the idea of “precision” in the “accuracy vs. precision” dichotomy.</p>
</div>
<div class="section" id="the-mean-squared-error-of-an-estimator">
<h2>The mean squared error of an estimator<a class="headerlink" href="#the-mean-squared-error-of-an-estimator" title="Permalink to this headline">¶</a></h2>
<div class="admonition-mean-squared-error admonition">
<p class="admonition-title">Mean squared error</p>
<p>The mean squared error of an estimator is defined by</p>
<div class="math notranslate nohighlight">
\[
\textrm{MSE}(\hat{\theta} \mid \theta) = \mathbb{E}[\left( \hat{\theta} - \theta \right)^2 \mid \theta ] = \textrm{var}(\hat{\theta} \mid \theta)) + (\textrm{bias}(\hat{\theta} \mid \theta))^2
\]</div>
<p><strong>Note</strong> the MSE also depends on the true, unknown value of <span class="math notranslate nohighlight">\(\theta\)</span>.</p>
</div>
</div>
<div class="section" id="the-bias-variance-tradeoff">
<h2>The bias-variance tradeoff<a class="headerlink" href="#the-bias-variance-tradeoff" title="Permalink to this headline">¶</a></h2>
<div class="tip admonition">
<p class="admonition-title">Food for thought</p>
<p>Which is better:</p>
<ul class="simple">
<li><p>an estimator <span class="math notranslate nohighlight">\(\hat{\theta}_1\)</span> that always has smaller bias than another <span class="math notranslate nohighlight">\(\hat{\theta}_2\)</span>,</p></li>
<li><p>the estimator <span class="math notranslate nohighlight">\(\hat{\theta}_2\)</span> that is always “closer” to the true value than <span class="math notranslate nohighlight">\(\hat{\theta}_1\)</span> (smaller MSE).</p></li>
</ul>
</div>
<p>Note how the MSE decomposes into two terms, the variance and the squared bias. This is one manifestation of the bias-variance tradeoff.
If you care about being close to the true value (smaller MSE), then you would be willing to trade a little bit of bias for a large reduction in variance.
As we will see, Bayesian estimators are often biased, and in some cases the MLE is (asymptotically) unbiased, but has large variance.
This is less of an issue when trying to infer a low-dimensional parameter <span class="math notranslate nohighlight">\(\theta\)</span>, but it becomes increasingly important as the dimensionality of <span class="math notranslate nohighlight">\(\theta\)</span> increases.</p>
<div class="admonition important">
<p class="admonition-title">Important</p>
<p>There’s no reason to confine yourself to bias, variance, or MSE to characterize the quality of your estimator. You could consider the bias to be 100 times more important than the variance, <span class="math notranslate nohighlight">\(\textrm{var}(\hat{\theta} \mid \theta)) + 100*(\textrm{bias}(\hat{\theta} \mid \theta))^2\)</span>, or a non-linear function of these two terms, or something that doesn’t explicitly involve bias or variance at all.
We can generalize these notions with the notions of <strong>loss</strong> and <strong>risk</strong> in <span class="xref myst">Statistical decision theory</span>.</p>
</div>
</div>
<div class="section" id="asymptotic-bias-and-variance">
<h2>Asymptotic bias and variance<a class="headerlink" href="#asymptotic-bias-and-variance" title="Permalink to this headline">¶</a></h2>
<p>Often it is useful to think about the properties of estimators as you add more data or “in the limit of a lot of data”. Those are informal concepts, that can be formalized by
considering a sequence of estimators <span class="math notranslate nohighlight">\(\hat{\theta}_k\)</span> with <span class="math notranslate nohighlight">\(k=1, \dots\)</span> where for each <span class="math notranslate nohighlight">\(k\)</span> the estimator takes as input <span class="math notranslate nohighlight">\(k\)</span> iid observations <span class="math notranslate nohighlight">\(\{X_i\}_{i=1}^k\)</span> with <span class="math notranslate nohighlight">\(X_i \sim p(X \mid \theta)\)</span>.
We can then study the <em>asymptotic limit</em>:</p>
<div class="math notranslate nohighlight">
\[
\lim_{k\to \infty} \textrm{SomeProperty}[\hat{\theta}_k \mid \theta ]
\]</div>
<div class="admonition-example admonition">
<p class="admonition-title">Example:</p>
<p>Consider a Gaussian distribution <span class="math notranslate nohighlight">\(G(X|\mu,\sigma^2)\)</span> and we wish to estimate the mean <span class="math notranslate nohighlight">\(\mu\)</span> and variance <span class="math notranslate nohighlight">\(\sigma^2\)</span> based on a dataset <span class="math notranslate nohighlight">\(\{x_i\}_{i=1}^N\)</span>.
This may seem like a boring example, and you may recognize the <span class="math notranslate nohighlight">\(N\)</span> vs. <span class="math notranslate nohighlight">\(N-1\)</span> from some previous classes, but there are two lessons here, so let’s go through it.</p>
<p>The maximum likelihood estimator for <span class="math notranslate nohighlight">\(\mu\)</span> is given by</p>
<div class="math notranslate nohighlight">
\[
\frac{\partial}{\partial \mu} \left( \sum_{i=1}^N -\log G(x_i | \mu, \sigma) \right) \bigg\rvert_{\hat{\mu}} = 0
\]</div>
<p>which leads to the familiar sample mean <span class="math notranslate nohighlight">\(\hat{\mu}_\textrm{MLE} = \bar{x} = \frac{1}{N}  \sum_{i=1}^N x_i\)</span>.</p>
<p>And if we think of the Gaussian parameterized in terms of the variance <span class="math notranslate nohighlight">\(\sigma^2\)</span>, instead of the standard deviation <span class="math notranslate nohighlight">\(\sigma\)</span>, we find</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\frac{\partial}{\partial \sigma^2} \left( \sum_{i=1}^N -\log G(x_i | \mu, \sigma) \right) \bigg\rvert_{\widehat{\sigma^2}} = 0 &amp;=&amp; \frac{\partial}{\partial\sigma^2} \sum_{i=1}^N  \left(  \frac{(x_i - \mu)^2}{2\sigma^2} + \log \sqrt{2 \pi \sigma^2} \right) \\
&amp;=&amp; \sum_{i=1}^N \left( -\frac{(x_i - \mu)^2}{2(\sigma^2)^2} + \frac{1}{2\sigma^2} \right)
\end{split}\]</div>
<p>Therefore</p>
<div class="math notranslate nohighlight">
\[
\widehat{\sigma^2}_\textrm{MLE} = S_N^2 = {\color{#DC2830}{\frac{1}{N}}} \sum_{i=1}^N (x_i - \bar{x})^2
\]</div>
<p>(Note the MLE is equivariant to reparameterization, so we could have done <span class="math notranslate nohighlight">\(\partial/\partial \sigma)\)</span> and we would arrive at the same answer.)</p>
<p>You may remember that this estimator is biased and that it is Better™ to use instead the unbiased estimator for the variance that includes <a class="reference external" href="https://en.wikipedia.org/wiki/Bessel%27s_correction">Bessel’s correction</a></p>
<div class="math notranslate nohighlight">
\[
\widehat{\sigma^2}_\textrm{Bessel} = S^2 = {\color{#0271AE}{\frac{1}{N-1}}} \sum_{i=1}^N (x_i - \bar{x})^2
\]</div>
<p>You may have even had some points deducted on homework or tests because you forgot to use <span class="math notranslate nohighlight">\(N-1\)</span> instead of <span class="math notranslate nohighlight">\(N\)</span>. And you may also remember thinking “That’s silly! What’s the big deal, <span class="math notranslate nohighlight">\(\color{#DC2830}{\frac{1}{N}}\)</span> and <span class="math notranslate nohighlight">\(\color{#0271AE}{\frac{1}{N-1}}\)</span> are essentially the same for large <span class="math notranslate nohighlight">\(N\)</span>. And you would be right.
That’s the statement that the maximum likelihood estimator is <strong>asymptotically unbiased</strong>.</p>
<p>You may have also wanted to estimate the standard deviation and used the seemingly obvious corrolary <span class="math notranslate nohighlight">\(\sqrt{ \color{#0271AE}{\frac{1}{N-1}} \sum_{i=1}^N (x_i - \bar{x})^2}\)</span>, being careful to use <span class="math notranslate nohighlight">\(N-1\)</span> like a diligent student of <a class="reference external" href="https://www.google.com/search?tbm=isch&amp;as_q=standard+deviation+N-1">poorly taught statistics</a>. However, that seemingly obvious corrolary is not actually motivated. While <span class="math notranslate nohighlight">\({\color{#0271AE}{\frac{1}{N-1}}} \sum_{i=1}^N (x_i - \bar{x})^2\)</span> is an unbiased estimator for the variance <span class="math notranslate nohighlight">\(\sigma^2\)</span>, <span class="math notranslate nohighlight">\(\sqrt{ \color{#0271AE}{\frac{1}{N-1}} \sum_{i=1}^N (x_i - \bar{x})^2}\)</span> is a biased estimator of <span class="math notranslate nohighlight">\(\sigma\)</span>!</p>
</div>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>The bias estimator is not equivariant to transformation of the estimator/estimand. This follows from the transformation properties of the the distribution when changing random variables, the Jacobian factor influences the mean.</p>
</div>
<div class="admonition caution">
<p class="admonition-title">Caution</p>
<p>What convention is used in <code class="docutils literal notranslate"><span class="pre">np.var(x)</span></code> and <code class="docutils literal notranslate"><span class="pre">np.std(x)</span></code>? Check the documentation <a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.std.html#numpy.std">numpy.std</a> and <a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.var">numpy.var</a>.</p>
</div>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./statistics"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        </div>
    </div>
    
    
    <div class='prev-next-bottom'>
        
    <a class='left-prev' id="prev-link" href="estimators.html" title="previous page">Estimators</a>
    <a class='right-next' id="next-link" href="investigation-bessels-correction.html" title="next page">Investigation of Bessel’s correction</a>

    </div>
    <footer class="footer mt-5 mt-md-0">
    <div class="container">
      <p>
        
          By Kyle Cranmer<br/>
        
            &copy; Copyright .<br/>
          <div class="extra_footer">
            <div>
<a href="https://creativecommons.org/licenses/by-nc-sa/4.0/"><img src="https://licensebuttons.net/l/by-nc-sa/3.0/88x31.png"></a>
    All content on this site (unless otherwise specified) is licensed under the <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0 license</a>
</div>

          </div>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>

    
  <script src="../_static/js/index.3da636dd464baa7582d2.js"></script>


    
    <!-- Google Analytics -->
    <script>
      window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
      ga('create', 'UA-178330963-1', 'auto');
      ga('set', 'anonymizeIp', true);
      ga('send', 'pageview');
    </script>
    <script async src='https://www.google-analytics.com/analytics.js'></script>
    <!-- End Google Analytics -->
    
  </body>
</html>